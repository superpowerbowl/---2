{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=5,padding=2),#3代表输入通道，16代表输出通道（16个卷积核）\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=5, padding=2),  # 3代表输入通道，16代表输出通道（16个卷积核）\n",
    "            nn.BatchNorm2d(128),  \n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=5, padding=2),  # 3代表输入通道，16代表输出通道（16个卷积核）\n",
    "            nn.BatchNorm2d(256),  \n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.layer4 =nn.Sequential(\n",
    "            nn.Conv2d(256, 64, kernel_size=3, padding=1),  # 3代表输入通道，16代表输出通道（16个卷积核）\n",
    "            nn.BatchNorm2d(64),  \n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 100)\n",
    "        #池化层\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.pool(self.layer2(out))\n",
    "        out = self.pool(self.layer3(out))\n",
    "        out = self.layer4(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        return out\n",
    "\n",
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
    "\n",
    "def load_data():\n",
    "    # 定义数据增强\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "    ])\n",
    "\n",
    "    transform_test = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "    ])\n",
    "\n",
    "    # 加载数据集\n",
    "    trainset = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=transform_train)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True, num_workers=8,pin_memory=True)\n",
    "\n",
    "    testset = torchvision.datasets.CIFAR100(root='./data', train=False, download=True, transform=transform_test)\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False, num_workers=8,pin_memory=True)\n",
    "\n",
    "    # 加载验证集\n",
    "    validset = torchvision.datasets.CIFAR100(root='./data', train=False, download=True, transform=transform_test)\n",
    "    validloader = torch.utils.data.DataLoader(validset, batch_size=32, shuffle=False, num_workers=8, pin_memory=True)\n",
    "\n",
    "    # 定义类别名称\n",
    "    classes = tuple(trainset.classes)\n",
    "    return trainloader,testloader,validloader,classes\n",
    "\n",
    "\n",
    "\n",
    "def get_model():\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    net = CNN().to(device)\n",
    "    return net,device\n",
    "\n",
    "def get_config(net):\n",
    "    # 定义损失函数和优化器\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=0.001, momentum=0.9, weight_decay=5e-4)\n",
    "    return criterion,optimizer\n",
    "\n",
    "def train_model(net, criterion, optimizer, trainloader, valloader, device,epochs=30):\n",
    "    # Train the model\n",
    "    net.to(device)\n",
    "    train_loss_list = []\n",
    "    train_acc_list = []\n",
    "    val_loss_list = []\n",
    "    val_acc_list = []\n",
    "    train_loss_iter_list = []\n",
    "    train_acc_iter_list = []\n",
    "    for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "        print(\"Epoch[{}/{}]:\".format(epoch + 1, epochs))\n",
    "        running_train_loss = 0.0\n",
    "        running_train_acc = 0.0\n",
    "        running_train_iter_loss = 0.0\n",
    "        running_train_iter_acc = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            acc = accuracy(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_train_iter_loss += loss.item()\n",
    "            running_train_iter_acc += acc.item()\n",
    "            running_train_loss += loss.item()\n",
    "            running_train_acc += acc.item()\n",
    "\n",
    "            if i % 100 == 99:  # print every 100 mini-batches\n",
    "                print('[%d, %5d] train_loss: %.3f, train_accuracy: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_train_iter_loss / 100, running_train_iter_acc / 100))\n",
    "                train_loss_iter_list.append(running_train_iter_loss / 100)\n",
    "                train_acc_iter_list.append(running_train_iter_acc / 100)\n",
    "                running_train_iter_loss = 0.0\n",
    "                running_train_iter_acc = 0.0\n",
    "\n",
    "        train_loss_list.append(running_train_loss / len(trainloader))\n",
    "        train_acc_list.append(running_train_acc / len(trainloader))\n",
    "        print('Epoch[ %d / %d ] : train_loss: %.3f, train_accuracy: %.3f' % (epoch + 1, epochs, running_train_loss / len(trainloader), running_train_acc / len(trainloader)))\n",
    "\n",
    "\n",
    "        # Evaluate the model on the validation set\n",
    "        running_val_loss = 0.0\n",
    "        running_val_acc = 0.0\n",
    "        with torch.no_grad():\n",
    "            for data in valloader:\n",
    "                inputs, labels = data[0].to(device), data[1].to(device)\n",
    "                outputs = net(inputs)\n",
    "                val_loss = criterion(outputs, labels)\n",
    "                val_acc = accuracy(outputs, labels)\n",
    "                running_val_loss += val_loss.item()\n",
    "                running_val_acc += val_acc.item()\n",
    "        val_loss_list.append(running_val_loss / len(valloader))\n",
    "        val_acc_list.append(running_val_acc / len(valloader))\n",
    "        print('Epoch[ %d / %d ] : val_loss: %.3f, val_accuracy: %.3f' %\n",
    "              (epoch+1, epochs, running_val_loss / len(valloader), running_val_acc / len(valloader)))\n",
    "        # 保存模型权重\n",
    "        best_val_acc = max(val_acc_list)\n",
    "        best_model_path = 'best_model.pth'\n",
    "        if running_val_acc / len(valloader) == best_val_acc:\n",
    "            torch.save(net.state_dict(), best_model_path)\n",
    "            print(f'Saved best model to {best_model_path}')\n",
    "    print('Finished Training')\n",
    "\n",
    "\n",
    "    plt.plot(train_loss_list, label='train')\n",
    "    plt.plot(val_loss_list, label='val')\n",
    "    plt.title('Loss Curve')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    plt.savefig('loss.png')\n",
    "\n",
    "    plt.plot(train_acc_list, label='train')\n",
    "    plt.plot(val_acc_list, label='val')\n",
    "    plt.title('Accuracy Curve')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    plt.savefig('accuracy.png')\n",
    "\n",
    "\n",
    "def test_model(net,testloader,criterion,device):\n",
    "    # Test the model\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    test_loss = 0.0\n",
    "    predictions=[]\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            test_loss += criterion(outputs, labels).item()\n",
    "            predictions.append(predicted.cpu().numpy())\n",
    "\n",
    "    print('test accuracy: %d %%' % (100 * correct / total))\n",
    "    print('Test loss: %.3f' % (test_loss / len(testloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader, testloader,validloader,classes=load_data()\n",
    "net,device = get_model()\n",
    "print('current device:  ', device)\n",
    "criterion,optimizer=get_config(net)\n",
    "train_model(net, criterion, optimizer, trainloader, validloader, device)\n",
    "test_model(net, testloader, criterion, device)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
